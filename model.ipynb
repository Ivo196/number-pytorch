{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. TUTORIAL: ¡PYTORCH DESDE CERO!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. El problema a resolver\n",
    "\n",
    "Supondremos un sencillo problema:\n",
    "\n",
    "Crear una Red Neuronal para clasificar imágenes de dígitos escritos a mano\n",
    "\n",
    "Así:\n",
    "\n",
    "La entrada a la Red Neuronal serán imágenes en escala de gris, de tamaño 28x28, que contendrán un dígito (entre 0 y 9) escrito a mano\n",
    "La Red Neuronal tendrá que aprender a clasificar estas imágenes en una de 10 posibles categorías (de 0 a 9).\n",
    "Así que el dato predicho por la Red Neuronal será una cantidad numérica (entre 0 y 9) que debería coincidir con el dígito escrito en la imagen de entrada\n",
    "Pero antes de implementar la Red debemos entender la forma como Pytorch procesa los datos.\n",
    "\n",
    "Comencemos hablando de los Tensores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Los tensores\n",
    "\n",
    "Un tensor es simplemente un arreglo de datos\n",
    "\n",
    "Este arreglo puede ser un vector (1 dimensión), una matriz (2 dimensiones) o puede tener 3 o más dimensiones.\n",
    "\n",
    "Los tensores son usados por Pytorch para almacenar todos los datos usados por el modelo de Deep Learning (datos de entrada, parámetros, datos de salida).\n",
    "\n",
    "Comencemos creando de forma manual un simple Tensor con cantidades numéricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Importamos la librería de Pytorch\n",
    "import torch \n",
    "\n",
    "# Creamos un tensor con valores numéricos\n",
    "arreglo = [[1, 2, 3], [4, 5, 6]] # 2 filas y 3 columnas\n",
    "tensor1 = torch.tensor(arreglo)\n",
    "print(tensor1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Usando: cuda\n"
     ]
    }
   ],
   "source": [
    "# Una característica importante de los Tensores es que los podemos almacenar en la CPU (por defecto) o en la GPU (lo que permite aprovechar su velocidad de cómputo).\n",
    "\n",
    "#Por ejemplo, veamos en qué dispositivo (device) está almacenado el tensor que acabamos de crear:\n",
    "\n",
    "from torch.cpu import is_available\n",
    "\n",
    "\n",
    "print(tensor1.device)\n",
    "\n",
    "#Si ahora nos conectamos a la GPU de Google Colab podemos almacenar esta información en una variable:\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Usando: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Y podemos almacenar el tensor en la GPU usando el método \"to\":\n",
    "tensor1 = tensor1.to(device)\n",
    "print(tensor1.device) #Con esto, si realizamos cualquier operación con este tensor ésta será realizada sobre la GPU (sobre esto volveremos en unos momentos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Y por ser un arreglo, un Tensor tiene atributos como por ejemplo su tamaño (shape):\n",
    "tensor1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Los Datasets y el set de datos\n",
    "En Pytorch existen dos módulos que nos permiten cargar sets de datos:\n",
    "\n",
    "torch.utils.data.Dataset: nos permite cargar datasets que se encuentran en la base de datos de Pytorch\n",
    "torch.utils.data.DataLoader: nos permite cargar datasets propios así como iterar sobre un Dataset.\n",
    "En este tutorial usaremos estos dos métodos:\n",
    "\n",
    "Primero usaremos torchvision.datasets para cargar el set de datos de imágenes de caracteres\n",
    "Más adelante usaremos torch.utils.data.DataLoader para iterar sobre el set de datos de imágenes y así entrenar y validar el modelo\n",
    "Comencemos usando torchvision.datasets para cargar un set de datos pre-existente.\n",
    "\n",
    "#### 4.1. Descargar el set de datos\n",
    "Usaremos el set de datos MNIST, el cual contiene un total de 60.000 imágenes cada una con un dígito (entre 0 y 9) escrito a mano. Además, por cada imagen se tiene su categoría correspondiente (una cantidad numérica entre 0 y 9).\n",
    "\n",
    "Comencemos descargando este set de datos desde la base de datos de Pytorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos las librerias necesarias\n",
    "from torchvision import datasets #Para descargar los datos\n",
    "from torchvision.transforms import ToTensor #Para convertir los datos en tensores\n",
    "import matplotlib.pyplot as plt #Para graficar los datos\n",
    "\n",
    "data_mnist = datasets.MNIST(\n",
    "    root=\"data\", #Ruta donde se guardaran los datos\n",
    "    train=True, #Se descargan los datos de entrenamiento\n",
    "    download=True, \n",
    "    transform=ToTensor() #Se convierten los datos en tensores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vemos caracteristicas de los datos\n",
    "data_mnist\n",
    "#Vemos que tiene un total de 60000 imagenes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Graficamos algunas images de ejemplo\n",
    "figure = plt.figure(figsize=(8,8))\n",
    "fils, cols = 3, 3\n",
    "\n",
    "for i in range(1, cols * fils + 1):\n",
    "    #Generamos un indice aleatorio\n",
    "    sample_idx = int(torch.randint(len(data_mnist), size=(1,)).item())\n",
    "    #Obtenemos la imagen y el label\n",
    "    img, label = data_mnist[sample_idx]\n",
    "    #Graficamos\n",
    "    figure.add_subplot(fils, cols, i)\n",
    "    plt.title(str(label)) #Categoria\n",
    "    plt.axis(\"off\") #No mostramos los ejes\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\") #Imagen (squeeze por que la imagen es de 1x28x28)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo de dato imagen: <class 'torch.Tensor'>\n",
      "Dimensiones de la imagen: torch.Size([1, 28, 28])\n",
      "Minimo y maximo imagen: 0.0, 1.0\n",
      "Tipo de categoria: <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "#Caracteristicas de una image\n",
    "print(f'Tipo de dato imagen: {type(img)}')\n",
    "print(f'Dimensiones de la imagen: {img.shape}')\n",
    "print(f'Minimo y maximo imagen: {img.min()}, {img.max()}')\n",
    "print(f'Tipo de categoria: {type(label)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen tiene estas características:\n",
    "\n",
    "Es un Tensor\n",
    "Tiene un tamaño de 1x28x28 (el 1 indica que es una imagen en escala de grises)\n",
    "Sus pixeles tienen valores entre 0 y 1\n",
    "Por otra parte es importante tener en cuenta que la categoría está por defecto almacenada como un entero (int) y no como un tensor. Esto implica que más adelante tendremos que convertir la categoría de cada imagen a un tensor para que pueda ser procesada por la Red Neuronal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Sets de entrenamiento, validación y prueba\n",
    "\n",
    "Siempre que construimos un modelo de Deep Learning debemos realizar la partición del set de datos en entrenamiento, validación y prueba.\n",
    "\n",
    "En este caso haremos la partición usando proporciones del 80, 10 y 10% respectivamente.\n",
    "\n",
    "Esto lo podemos lograr fácilmente usando el método random_split de Pytorch.\n",
    "\n",
    "Para ello, primero fijamos la semilla del generador de números aleatorio de Pytorch, lo que garantizará que cada vez que ejecutemos el código obtendremos las mismas particiones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1857ff63970>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de imagenes en el set de entrenamiento: 48000, <class 'torch.utils.data.dataset.Subset'>\n",
      "Total de imagenes en el set de validacion: 6000, <class 'torch.utils.data.dataset.Subset'>\n",
      "Total de imagenes en el set de prueba: 6000, <class 'torch.utils.data.dataset.Subset'>\n"
     ]
    }
   ],
   "source": [
    "train, val, test = torch.utils.data.random_split(\n",
    "    data_mnist,\n",
    "    [0.8,0.1,0.1]\n",
    ")\n",
    "print(f'Total de imagenes en el set de entrenamiento: {len(train)}, {type(train)}')\n",
    "print(f'Total de imagenes en el set de validacion: {len(val)}, {type(val)}')\n",
    "print(f'Total de imagenes en el set de prueba: {len(test)}, {type(test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y vemos que los tres subsets de datos son de tipo dataset.\n",
    "\n",
    "Ya estamos listos para ver cómo crear el modelo (la Red Neuronal)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. ¿Cómo crear un modelo de Deep Learning?\n",
    "\n",
    "Crearemos una sencilla Red Neuronal con estas características:\n",
    "\n",
    "Capa de entrada: 28x28 = 784 elementos\n",
    "Capa oculta: 15 neuronas, activación ReLU\n",
    "Capa de salida: 10 neuronas (1 por cada categoría a predecir), activación softmax5. ¿Cómo crear un modelo de Deep Learning?\n",
    "Crearemos una sencilla Red Neuronal con estas características:\n",
    "\n",
    "Capa de entrada: 28x28 = 784 elementos\n",
    "Capa oculta: 15 neuronas, activación ReLU\n",
    "Capa de salida: 10 neuronas (1 por cada categoría a predecir), activación softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionalmente, antes de llevar cada imagen a la Red tendremos que aplanarla para convertirla de un tensor 3D de 1x28x28 a un tensor de 1D de 28x28 = 784 (el mismo tamaño de la capa de entrada de la Red)\n",
    "Para crear la Red Neuronal debemos crear una sub-clase de nn.Module. Veamos cómo hacerlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos modulo nn\n",
    "from torch import nn \n",
    "\n",
    "# Crear la Red Neuronal como una subclase de nn.Module\n",
    "# Siempre se añaden dos métodos a esta subclase\n",
    "# 1. Método \"init\": define la arquitectura de la red\n",
    "# 2. Método \"forward\": define cómo será generada cada predicción\n",
    "\n",
    "# Creamos una sub-clase de nn.Module\n",
    "class RedNeuronal(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        #Agregamos secuencialmente las capas de la red\n",
    "        self.aplanar = nn.Flatten() #Aplana las imagenes de 1x28x28 a 1D de 784 elementos\n",
    "        self.red = nn.Sequential(\n",
    "            nn.Linear(28*28, 15), #Capa de entrada + capa oculta\n",
    "            nn.ReLU(), #Activacion ReLU\n",
    "            nn.Linear(15, 10) #Capa de salida\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.aplanar(x)\n",
    "        logits = self.red(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota: a pesar de que la capa de salida debería tener una activación softmax esta no se incluye porque no es necesaria para el entrenamiento (sólo es necesaria para garantizar que las salidas de cada neurona de salida suman exactamente 1).\n",
    "\n",
    "Habiendo creado la clase ya podemos crear la Red Neuronal simplemente:\n",
    "\n",
    "Creando una instancia de la clase RedNeuronal\n",
    "Y moviendo esta instancia a la GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RedNeuronal(\n",
      "  (aplanar): Flatten(start_dim=1, end_dim=-1)\n",
      "  (red): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=15, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=15, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "modelo = RedNeuronal().to(device)\n",
    "print(modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de parametros a entrenar: 11935\n"
     ]
    }
   ],
   "source": [
    "# Podemos usar el método parameters() para imprimir en pantalla el número de parámetros a entrenar en este modelo:\n",
    "total_params = sum(p.numel()for p in modelo.parameters())\n",
    "print(f'Numero de parametros a entrenar: {total_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Propagación hacia adelante y hacia atrás\n",
    "La propagación hacia adelante y hacia atrás son las dos fases clave al momento de entrenar la Red Neuronal.\n",
    "\n",
    "Veamos cada fase en detalle:\n",
    "\n",
    "6.1. Propagación hacia adelante (forward propagation)\n",
    "Con la propagación hacia adelante se toma el dato de entrada ( X ), la Red lo procesa y genera una predicción ( ypred  ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "# Extraer una imagen y su categoría del set de entrenamiento\n",
    "img, lbl = train[200]\n",
    "\n",
    "print(type(img))\n",
    "print(type(lbl))\n",
    "#Vemos que la imagen es un Tensor mientras que la categoría es un entero. Debemos convertir esta categoría a un tensor para poder presentarla al modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Convertir \"lbl\" a Tensor usando \"tensor\", definir tamaño igual a 1 (1 dato)\n",
    "# con \"reshape\"\n",
    "lbl = torch.tensor(lbl).reshape(1)\n",
    "print(type(lbl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora llevamos tanto el dato como su categoría a la GPU:\n",
    "img, lbl = img.to(device), lbl.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2088, -0.1774,  0.2579,  0.1910,  0.0531, -0.1378, -0.1164, -0.0240,\n",
      "         -0.3448,  0.0655]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "logits = modelo(img)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2], device='cuda:0')\n",
      "Logits: tensor([[-0.2088, -0.1774,  0.2579,  0.1910,  0.0531, -0.1378, -0.1164, -0.0240,\n",
      "         -0.3448,  0.0655]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Categoría predicha: 2\n",
      "Categoría real: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAHBpJREFUeJzt3X9sVfX9x/FXKfSC0N5aan/JDwsqLCLdhlA7leHoaLuFiDKjziXgjARXzJD5Y12U6pypw2Q6HVOjG52Z+CsZEHFp1GpLnAVDlTEzbWhTbB1tUWbvLcUW0n6+f/D1jisFPJd7+763PB/JJ2nPOe+etx9P+uLce/q5Sc45JwAAhtko6wYAAGcmAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmRls38FWDg4Pat2+fUlNTlZSUZN0OAMAj55x6enqUl5enUaNOfJ8TdwG0b98+TZ482boNAMBpam9v16RJk064P+5egktNTbVuAQAQBaf6fR6zAFq/fr3OO+88jR07VoWFhXr33Xe/Vh0vuwHAyHCq3+cxCaAXX3xRa9asUWVlpd577z0VFBSopKRE+/fvj8XpAACJyMXAvHnzXHl5eej7gYEBl5eX56qqqk5ZGwgEnCQGg8FgJPgIBAIn/X0f9Tugw4cPq7GxUcXFxaFto0aNUnFxsRoaGo47vr+/X8FgMGwAAEa+qAfQZ599poGBAWVnZ4dtz87OVmdn53HHV1VVye/3hwZPwAHAmcH8KbiKigoFAoHQaG9vt24JADAMov53QJmZmUpOTlZXV1fY9q6uLuXk5Bx3vM/nk8/ni3YbAIA4F/U7oJSUFM2ZM0e1tbWhbYODg6qtrVVRUVG0TwcASFAxWQlhzZo1WrZsmS655BLNmzdPjz76qHp7e3XTTTfF4nQAgAQUkwC67rrr9Omnn2rt2rXq7OzUN7/5TdXU1Bz3YAIA4MyV5Jxz1k0cKxgMyu/3W7cBADhNgUBAaWlpJ9xv/hQcAODMRAABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAE6OtGwBiYfToyC7thoYGzzWvvPKK55rx48d7ronE008/HVHdjTfe6LnmrLPO8lzT09Pjuebhhx/2XNPf3++5BrHHHRAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATSc45Z93EsYLBoPx+v3UbSHDLly+PqO7Pf/5zdBtB1L311lueayorKyM619tvvx1RHY4KBAJKS0s74X7ugAAAJgggAICJqAfQfffdp6SkpLAxc+bMaJ8GAJDgYvKBdBdddJHeeOON/50kwg8HAwCMXDFJhtGjRysnJycWPxoAMELE5D2gPXv2KC8vT9OmTdONN96otra2Ex7b39+vYDAYNgAAI1/UA6iwsFDV1dWqqanRE088odbWVl1xxRUn/Oz3qqoq+f3+0Jg8eXK0WwIAxKGoB1BZWZmuvfZazZ49WyUlJfr73/+u7u5uvfTSS0MeX1FRoUAgEBrt7e3RbgkAEIdi/nRAenq6LrzwQjU3Nw+53+fzyefzxboNAECcifnfAR08eFAtLS3Kzc2N9akAAAkk6gF0xx13qL6+Xnv37tU777yjq6++WsnJybrhhhuifSoAQAKL+ktwn3zyiW644QYdOHBA55xzji6//HJt375d55xzTrRPBQBIYCxGirj31FNPea756U9/GtG5kpOTPde0trZ6rvnss8881zz33HOea0pLSz3XSNLEiRMjqvMqJSXFc01BQYHnmk8//dRzjSQ988wznmseeOABzzV9fX2eaxIBi5ECAOISAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEyxGimH19NNPe675yU9+4rnmRJ/AeyrV1dWeaz788EPPNZ2dnZ5rRqKxY8d6rnn88cc919x8882eayJ1wQUXeK5paWmJQSf2WIwUABCXCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmWA0bEcvLy/Nc884773iumTJliueaadOmea6RpL1790ZUh+Ezbtw4zzVvvPFGROcqKiryXPPggw96rrn33ns91yQCVsMGAMQlAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJkZbN4DENXv2bM81kSws+q9//ctzTUdHh+caJIYvvvjCc826desiOtemTZs812RlZUV0rjMRd0AAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMsBgpdO6550ZU9/vf/z7KnQztoYce8lzT398fg06QqILB4LCd66abbvJcc/fdd3uu6e7u9lwTb7gDAgCYIIAAACY8B9C2bdu0ePFi5eXlKSkpSZs3bw7b75zT2rVrlZubq3Hjxqm4uFh79uyJVr8AgBHCcwD19vaqoKBA69evH3L/unXr9Nhjj+nJJ5/Ujh07NH78eJWUlKivr++0mwUAjByeH0IoKytTWVnZkPucc3r00Ud1zz336KqrrpIkPfvss8rOztbmzZt1/fXXn163AIARI6rvAbW2tqqzs1PFxcWhbX6/X4WFhWpoaBiypr+/X8FgMGwAAEa+qAZQZ2enJCk7Oztse3Z2dmjfV1VVVcnv94fG5MmTo9kSACBOmT8FV1FRoUAgEBrt7e3WLQEAhkFUAygnJ0eS1NXVFba9q6srtO+rfD6f0tLSwgYAYOSLagDl5+crJydHtbW1oW3BYFA7duxQUVFRNE8FAEhwnp+CO3jwoJqbm0Pft7a2ateuXcrIyNCUKVO0evVq/eY3v9EFF1yg/Px83XvvvcrLy9OSJUui2TcAIMF5DqCdO3fqyiuvDH2/Zs0aSdKyZctUXV2tu+66S729vVqxYoW6u7t1+eWXq6amRmPHjo1e1wCAhJfknHPWTRwrGAzK7/dbt3FGOfYfFF4c+1JrLE2dOtVzDQ+z4Fjxfo1PnDjRc83nn38eg06iKxAInPR9ffOn4AAAZyYCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAnPH8eAkae8vHzYzvXqq696rvnvf/8bg06A2Oju7vZcMzAwEP1GEgB3QAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEywGOkIc8kll3iu+c53vhODToZ2zz33eK7p7e2NQSc4k/zoRz8atnPdcMMNnmuCwWAMOol/3AEBAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwwWKkI8yKFSs81+Tk5MSgEyA2ysrKPNdEskBopJqbm4ftXImOOyAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmWIwUEXv77bc91zQ1NcWgEySqCRMmeK5Zu3at55r09HTPNZL02muvea5pb2+P6FxnIu6AAAAmCCAAgAnPAbRt2zYtXrxYeXl5SkpK0ubNm8P2L1++XElJSWGjtLQ0Wv0CAEYIzwHU29urgoICrV+//oTHlJaWqqOjIzSef/7502oSADDyeH4Ioays7JSfSOjz+fiUTQDAScXkPaC6ujplZWVpxowZuvXWW3XgwIETHtvf369gMBg2AAAjX9QDqLS0VM8++6xqa2v129/+VvX19SorK9PAwMCQx1dVVcnv94fG5MmTo90SACAORf3vgK6//vrQ1xdffLFmz56t6dOnq66uTgsXLjzu+IqKCq1Zsyb0fTAYJIQA4AwQ88ewp02bpszMTDU3Nw+53+fzKS0tLWwAAEa+mAfQJ598ogMHDig3NzfWpwIAJBDPL8EdPHgw7G6mtbVVu3btUkZGhjIyMnT//fdr6dKlysnJUUtLi+666y6df/75KikpiWrjAIDE5jmAdu7cqSuvvDL0/Zfv3yxbtkxPPPGEdu/erb/85S/q7u5WXl6eFi1apAceeEA+ny96XQMAEl6Sc85ZN3GsYDAov99v3UZcOPvssz3X/Oc///FcM3bsWM81krR48WLPNa+++mpE50L8Gz9+vOeavXv3eq6ZOHGi55pIFwiN5JWbjz76KKJzjUSBQOCk7+uzFhwAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwETUP5Ib0XPppZd6rolkZevBwUHPNZLU09MTUR3i34IFCzzX1NTUeK6J5GNaPv74Y881xcXFnmsknfCTnBEd3AEBAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwwWKkcczv9w/LeRobGyOq27ZtW5Q7QbQtWrQoorpNmzZ5rolkYdG9e/d6rvn+97/vuYZFReMTd0AAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMsBhpHPvWt75l3QJiZMKECZ5rSktLPdc888wznmskady4cZ5rPv74Y881LCx6ZuMOCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkWI41jbW1tw3KetLS0iOrOPvtszzWff/55ROcaLj6fz3PNgw8+6Lnmiiuu8Fwzd+5czzWRam9v91xTXFzsuYaFRc9s3AEBAEwQQAAAE54CqKqqSnPnzlVqaqqysrK0ZMkSNTU1hR3T19en8vJyTZw4URMmTNDSpUvV1dUV1aYBAInPUwDV19ervLxc27dv1+uvv64jR45o0aJF6u3tDR1z++2365VXXtHLL7+s+vp67du3T9dcc03UGwcAJDZPDyHU1NSEfV9dXa2srCw1NjZq/vz5CgQC+tOf/qSNGzfqe9/7niRpw4YN+sY3vqHt27fr0ksvjV7nAICEdlrvAQUCAUlSRkaGJKmxsVFHjhwJexpm5syZmjJlihoaGob8Gf39/QoGg2EDADDyRRxAg4ODWr16tS677DLNmjVLktTZ2amUlBSlp6eHHZudna3Ozs4hf05VVZX8fn9oTJ48OdKWAAAJJOIAKi8v1wcffKAXXnjhtBqoqKhQIBAIjUj+/gAAkHgi+kPUVatWaevWrdq2bZsmTZoU2p6Tk6PDhw+ru7s77C6oq6tLOTk5Q/4sn88X0R//AQASm6c7IOecVq1apU2bNunNN99Ufn5+2P45c+ZozJgxqq2tDW1rampSW1ubioqKotMxAGBE8HQHVF5ero0bN2rLli1KTU0Nva/j9/s1btw4+f1+3XzzzVqzZo0yMjKUlpam2267TUVFRTwBBwAI4ymAnnjiCUnSggULwrZv2LBBy5cvlyQ98sgjGjVqlJYuXar+/n6VlJToj3/8Y1SaBQCMHEnOOWfdxLGCwaD8fr91G3EhNTXVc80///lPzzXnnXee5xpJx62C8XXs2LHDc83WrVs91yQnJ3uukaRf/vKXnmsKCgoiOtdweO211yKqW716teeajz76KKJzYeQKBAInXeyYteAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACZYDXuEWbVqleeaxx57LAad4GS6uro81zzyyCOeax599FHPNZJ0+PDhiOqAY7EaNgAgLhFAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADDBYqQjTHJysueaGTNmRHSuyspKzzXXXnttROcaLr29vZ5r/vCHP3iuefHFFz3X7Nq1y3MNYInFSAEAcYkAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJFiMFAMQEi5ECAOISAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMeAqgqqoqzZ07V6mpqcrKytKSJUvU1NQUdsyCBQuUlJQUNlauXBnVpgEAic9TANXX16u8vFzbt2/X66+/riNHjmjRokXq7e0NO+6WW25RR0dHaKxbty6qTQMAEt9oLwfX1NSEfV9dXa2srCw1NjZq/vz5oe1nnXWWcnJyotMhAGBEOq33gAKBgCQpIyMjbPtzzz2nzMxMzZo1SxUVFTp06NAJf0Z/f7+CwWDYAACcAVyEBgYG3A9/+EN32WWXhW1/6qmnXE1Njdu9e7f761//6s4991x39dVXn/DnVFZWOkkMBoPBGGEjEAicNEciDqCVK1e6qVOnuvb29pMeV1tb6yS55ubmIff39fW5QCAQGu3t7eaTxmAwGIzTH6cKIE/vAX1p1apV2rp1q7Zt26ZJkyad9NjCwkJJUnNzs6ZPn37cfp/PJ5/PF0kbAIAE5imAnHO67bbbtGnTJtXV1Sk/P/+UNbt27ZIk5ebmRtQgAGBk8hRA5eXl2rhxo7Zs2aLU1FR1dnZKkvx+v8aNG6eWlhZt3LhRP/jBDzRx4kTt3r1bt99+u+bPn6/Zs2fH5D8AAJCgvLzvoxO8zrdhwwbnnHNtbW1u/vz5LiMjw/l8Pnf++ee7O++885SvAx4rEAiYv27JYDAYjNMfp/rdn/T/wRI3gsGg/H6/dRsAgNMUCASUlpZ2wv2sBQcAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMBF3AeScs24BABAFp/p9HncB1NPTY90CACAKTvX7PMnF2S3H4OCg9u3bp9TUVCUlJYXtCwaDmjx5strb25WWlmbUoT3m4Sjm4Sjm4Sjm4ah4mAfnnHp6epSXl6dRo058nzN6GHv6WkaNGqVJkyad9Ji0tLQz+gL7EvNwFPNwFPNwFPNwlPU8+P3+Ux4Tdy/BAQDODAQQAMBEQgWQz+dTZWWlfD6fdSummIejmIejmIejmIejEmke4u4hBADAmSGh7oAAACMHAQQAMEEAAQBMEEAAABMJE0Dr16/Xeeedp7Fjx6qwsFDvvvuudUvD7r777lNSUlLYmDlzpnVbMbdt2zYtXrxYeXl5SkpK0ubNm8P2O+e0du1a5ebmaty4cSouLtaePXtsmo2hU83D8uXLj7s+SktLbZqNkaqqKs2dO1epqanKysrSkiVL1NTUFHZMX1+fysvLNXHiRE2YMEFLly5VV1eXUcex8XXmYcGCBcddDytXrjTqeGgJEUAvvvii1qxZo8rKSr333nsqKChQSUmJ9u/fb93asLvooovU0dERGm+//bZ1SzHX29urgoICrV+/fsj969at02OPPaYnn3xSO3bs0Pjx41VSUqK+vr5h7jS2TjUPklRaWhp2fTz//PPD2GHs1dfXq7y8XNu3b9frr7+uI0eOaNGiRert7Q0dc/vtt+uVV17Ryy+/rPr6eu3bt0/XXHONYdfR93XmQZJuueWWsOth3bp1Rh2fgEsA8+bNc+Xl5aHvBwYGXF5enquqqjLsavhVVla6goIC6zZMSXKbNm0KfT84OOhycnLcww8/HNrW3d3tfD6fe/755w06HB5fnQfnnFu2bJm76qqrTPqxsn//fifJ1dfXO+eO/r8fM2aMe/nll0PHfPjhh06Sa2hosGoz5r46D845993vftf9/Oc/t2vqa4j7O6DDhw+rsbFRxcXFoW2jRo1ScXGxGhoaDDuzsWfPHuXl5WnatGm68cYb1dbWZt2SqdbWVnV2doZdH36/X4WFhWfk9VFXV6esrCzNmDFDt956qw4cOGDdUkwFAgFJUkZGhiSpsbFRR44cCbseZs6cqSlTpozo6+Gr8/Cl5557TpmZmZo1a5YqKip06NAhi/ZOKO4WI/2qzz77TAMDA8rOzg7bnp2drY8++sioKxuFhYWqrq7WjBkz1NHRofvvv19XXHGFPvjgA6Wmplq3Z6Kzs1OShrw+vtx3pigtLdU111yj/Px8tbS06Fe/+pXKysrU0NCg5ORk6/aibnBwUKtXr9Zll12mWbNmSTp6PaSkpCg9PT3s2JF8PQw1D5L04x//WFOnTlVeXp52796tu+++W01NTfrb3/5m2G24uA8g/E9ZWVno69mzZ6uwsFBTp07VSy+9pJtvvtmwM8SD66+/PvT1xRdfrNmzZ2v69Omqq6vTwoULDTuLjfLycn3wwQdnxPugJ3OieVixYkXo64svvli5ublauHChWlpaNH369OFuc0hx/xJcZmamkpOTj3uKpaurSzk5OUZdxYf09HRdeOGFam5utm7FzJfXANfH8aZNm6bMzMwReX2sWrVKW7du1VtvvRX28S05OTk6fPiwuru7w44fqdfDieZhKIWFhZIUV9dD3AdQSkqK5syZo9ra2tC2wcFB1dbWqqioyLAzewcPHlRLS4tyc3OtWzGTn5+vnJycsOsjGAxqx44dZ/z18cknn+jAgQMj6vpwzmnVqlXatGmT3nzzTeXn54ftnzNnjsaMGRN2PTQ1NamtrW1EXQ+nmoeh7Nq1S5Li63qwfgri63jhhRecz+dz1dXV7t///rdbsWKFS09Pd52dndatDatf/OIXrq6uzrW2trp//OMfrri42GVmZrr9+/dbtxZTPT097v3333fvv/++k+R+97vfuffff999/PHHzjnnHnroIZeenu62bNnidu/e7a666iqXn5/vvvjiC+POo+tk89DT0+PuuOMO19DQ4FpbW90bb7zhvv3tb7sLLrjA9fX1WbceNbfeeqvz+/2urq7OdXR0hMahQ4dCx6xcudJNmTLFvfnmm27nzp2uqKjIFRUVGXYdfaeah+bmZvfrX//a7dy507W2trotW7a4adOmufnz5xt3Hi4hAsg55x5//HE3ZcoUl5KS4ubNm+e2b99u3dKwu+6661xubq5LSUlx5557rrvuuutcc3OzdVsx99ZbbzlJx41ly5Y5544+in3vvfe67Oxs5/P53MKFC11TU5Nt0zFwsnk4dOiQW7RokTvnnHPcmDFj3NSpU90tt9wy4v6RNtR/vyS3YcOG0DFffPGF+9nPfubOPvtsd9ZZZ7mrr77adXR02DUdA6eah7a2Njd//nyXkZHhfD6fO//8892dd97pAoGAbeNfwccxAABMxP17QACAkYkAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAICJ/wMPzAf1n1LLkgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#La predicción (o logits) es un arreglo no normalizado de 10 valores numéricos (puesto que tenemos 10 categorías).\n",
    "\n",
    "#No normalizado implica que su suma no es igual a 1. Para normalizarlo se puede usar la función softmax aunque no es necesario, podemos calcular la categoría predicha simplemente encontrando la posición donde se encuentre el valor máximo:\n",
    "\n",
    "y_pred = logits.argmax(dim=1)\n",
    "print(y_pred)\n",
    "\n",
    "# Mostremos la imagen \n",
    "plt.imshow(img.cpu().squeeze(), cmap='gray')\n",
    "\n",
    "print(f'Logits: {logits}')\n",
    "print(f'Categoría predicha: {y_pred[0]}')\n",
    "print(f'Categoría real: {lbl[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Es de esperar que la categoría predicha (2) o coincida con la categoría real (0) pesto que no hemos entrenado la Red Neuronal!\n",
    "\n",
    "Veamos ahora la segunda fase que hace parte del entrenamiento: la propagación hacia atrás.\n",
    "\n",
    "6.2. Propagación hacia atrás (backward propagation o backprop)\n",
    "Esta propagación hacia atrás permite actualizar los parámetros del modelo con base en el gradiente de la pérdida.\n",
    "\n",
    "La idea básica es ajustar estos parámetros para minimizar la pérdida (mejorando así las predicciones).\n",
    "\n",
    "Los pasos involucrados en esta propagación hacia atrás son:\n",
    "\n",
    "Definir la pérdida (función que se usará para comparar las predicciones con las categorías reales) y el optimizador (algoritmo que se usará para ajustar los parámetros y minimizar la pérdida)\n",
    "Tomar cada predicción (logits), compararla con la categoría real correspondiente (y) y calcular la pérdida (loss)\n",
    "Calcular los gradientes de la pérdida (derivadas con respecto a cada parámetro)\n",
    "Actualizar los parámetros del modelo usando los gradientes y un algoritmo de optimización (como por ejemplo el Gradiente Descendente):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos cómo implementar cada uno de estos pasos.\n",
    "\n",
    "Comencemos definiendo la función de pérdida (entropía cruzada) y el optimizador a usar (Gradiente Descendente). En este último caso usaremos una tasa de aprendizaje de 0.2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_perdida = nn.CrossEntropyLoss()\n",
    "optimizador = torch.optim.SGD(modelo.parameters(), lr=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que al definir el optimizador el primer argumento son los parámetros del modelo (modelo.parameters()).\n",
    "\n",
    "Esto permite \"conectar\" el modelo al optimizador de tal manera que durante el entrenamiento el optimizador pueda ajustar los parámetros para mejorar las predicciones.\n",
    "\n",
    "Ahora tomamos la predicción (que se obtuvo con la propagación hacia adelante), la comparamos con la categoría real y calculamos la pérdida. La\n",
    "\n",
    "Esto se hace con una sola línea de código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4832, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = fn_perdida(logits, lbl)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora calculamos los gradientes de la pérdida. Esto logra usando el método backward() asociado a la variable loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y finalmente actualizamos los parámetros del modelo usando el optimizador.\n",
    "\n",
    "Esto se logra en dos pasos:\n",
    "\n",
    "1. Usando el método `step()` que actualiza los parámetros del modelo\n",
    "2. Usando el método `zero_grad()` para explícitamente borrar los gradientes calculados anteriormente (pues Pytorch los deja almacenados y esto afecta el entrenamiento).\n",
    "\n",
    "Estos dos pasos los podemos implementar en dos líneas de código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizador.step()\n",
    "optimizador.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y listo, ya tenemos la propagación hacia atrás.\n",
    "\n",
    "Así que para resumir, re-escribamos todas las líneas de código anteriores para combinar en un sólo bloque la propagación hacia adelante y hacia atrás:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img: dato, lbl: categoría real\n",
    "\n",
    "# Propagación hacia adelante (generar predicciones)\n",
    "logits = modelo(img)\n",
    "\n",
    "# Propagación hacia atrás\n",
    "loss = fn_perdida(logits, lbl) # Perdida\n",
    "loss.backward() # Calcular gradientes\n",
    "optimizador.step() # Actualizar parámetros del modelo\n",
    "optimizador.zero_grad() # Borrar gradientes calculados anteriormente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y listo, tenemos en muy pocas líneas de código los dos pasos esenciales en el entrenamiento de cualquier modelo de Deep Learning: forward + back propagation.\n",
    "\n",
    "Al entrenar el modelo no usaremos una sola imagen sino que usaremos todo el set de entrenamiento. Y además repetiremos la anterior celda de código varias veces (el número de iteraciones de entrenamiento que definamos).\n",
    "\n",
    "Así que con todo lo visto hasta este punto ya estamos listos para conectar todos estos elementos y ver cómo se crea, entrena y valida nuestra Red Neuronal para clasificar imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Entrenando y validando un modelo: ejemplo completo\n",
    "En esta última parte simplemente tomaremos las porciones de código de las secciones anteriores y las organizaremos para entender la lógica de creación, entrenamiento y validación de la Red Neuronal.\n",
    "\n",
    "Veamos todo esto en detalle.\n",
    "\n",
    "7.1. Creación de la Red Neuronal\n",
    "Escribamos en una sola celda el código necesario para crear la clase y la instancia correspondiente a nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clase\n",
    "class RedNeuronal(nn.Module):\n",
    "    # 1. Método \"init\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Y agregar secuencialmente las capas\n",
    "        self.aplanar = nn.Flatten() # Aplanar imágenes de entrada\n",
    "        self.red = nn.Sequential(\n",
    "            nn.Linear(28*28, 15), # Capa de entrada + capa oculta\n",
    "            nn.ReLU(), # Función de activación capa oculta\n",
    "            nn.Linear(15,10), # Capa de salida SIN activación\n",
    "        )\n",
    "\n",
    "    # 2. Método \"forward\" (x = dato de entrada)\n",
    "    def forward(self, x):\n",
    "        # Definir secuencialmente las operaciones a aplicar\n",
    "        x = self.aplanar(x) # Aplanar dato\n",
    "        logits = self.red(x) # Generar predicción\n",
    "\n",
    "        return logits\n",
    "\n",
    "# Instancia (llevada a la GPU)\n",
    "modelo = RedNeuronal().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de entrenar la Red (usando el código para la propagación hacia adelante y hacia atrás), debemos preparar nuestros set de entrenamiento y validación. Veamos cómo hacer esto.\n",
    "7.2. Preparar los sets de entrenamiento y validación\n",
    "El set de entrenamiento nos permitirá usar la propagación hacia adelante y hacia atrás para automáticamente actualizar los parámetros del modelo.\n",
    "\n",
    "Por su parte el set de validación se usará para que tras cada iteración de entrenamiento, pongamos a prueba el modelo y verifiquemos su desempeño.\n",
    "\n",
    "Como tenemos muchos datos de entrenamiento (48.000) y muchos de validación (6.000) no podemos presentarlos en bloque al modelo pues habría problemas con la memoria RAM.\n",
    "\n",
    "En lugar de ello los presentamos por lotes (batches), es decir pequeños grupos de datos.\n",
    "\n",
    "Para poder crear estos lotes y presentarlos al modelo usamos DataLoaderel segundo módulo de procesamiento de datos que posee Pytorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "TAM_LOTE = 1000 # batch size\n",
    "\n",
    "# Creamos el DataLoader para el set de entrenamiento y vali\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train,\n",
    "    batch_size=TAM_LOTE,\n",
    "    shuffle=True, # Mezclamos los datos \n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val,\n",
    "    batch_size=TAM_LOTE,\n",
    "    shuffle=False, # No mezclamos los datos\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando entrenemos y validemos el modelo le presentaremos, en cada iteración, las variables train_loader y val_loader para que se realice el entrenamiento y la validación.\n",
    "\n",
    "Así que ya tenemos todo listo para realizar este entrenamiento y validación de la red. Veamos el código.\n",
    "\n",
    "7.3. Entrenamiento y validación del modelo\n",
    "Comencemos definiendo los hiper-parámetros: la tasa de aprendizaje del algoritmo de optimización y el número de iteraciones de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASA_APRENDIZAJE = 0.1 # learning rate\n",
    "EPOCHS = 10 # epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_perdida = nn.CrossEntropyLoss()\n",
    "optimizador = torch.optim.SGD(modelo.parameters(), lr=TASA_APRENDIZAJE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora crearemos la función train_loop que se ejecutará en cada iteración del entrenamiento.\n",
    "\n",
    "Esta función usa las dos fases vistas anteriormente: propagación hacia adelante y hacia atrás.\n",
    "\n",
    "Además, en cada iteración calcularemos dos variables que nos permitirán monitorear el progreso del entrenamiento:\n",
    "\n",
    "perdida_train: valores promedio de la función de pérdida en cada iteración\n",
    "exactitud: valores promedio (en cada iteración) de la exactitud del modelo al momento de clasificar los datos. La exactitud es simplemente el porcentaje de datos clasificados correctamente con respecto al total de datos clasificados.\n",
    "Veamos cómo implementar esta función:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    # Cantidad de datos de entrenamiento y cantidad de lotes\n",
    "    train_size = len(dataloader.dataset) #48000\n",
    "    nlotes = len(dataloader) #48\n",
    "\n",
    "    #Indicarle a Pytorch que el modelo está en modo entrenamiento\n",
    "    modelo.train()\n",
    "\n",
    "    # Inicializar acumuladores de pérdida y exactitud\n",
    "    perdida_train, exactitud = 0, 0\n",
    "\n",
    "    for nlote, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Propagación hacia adelante\n",
    "        logits = model(X)\n",
    "\n",
    "        # Propagación hacia atrás\n",
    "        loss = loss_fn(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Acumular valores de pérdida y exactitud\n",
    "        # perdida_train <- perdida_train + perdida_actual\n",
    "        # exactitud <- exactitud + numero_aciertos_actuales\n",
    "        perdida_train += loss.item()\n",
    "        exactitud += (logits.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "        # Imprimimos la evolucion del entrenamiento cada 10 lotes\n",
    "        if nlote % 10 == 0: #Cuando sea un multiplo de 10 imprimimos\n",
    "            # Optenemos el valor de la perdida actual y el numero de datos procesados\n",
    "            ndatos = nlote*TAM_LOTE #Cantidad de datos procesados\n",
    "\n",
    "            print(f\"\\tPerdida: {loss.item():>7f} [{ndatos:>5d}/{train_size:>5d}]\")\n",
    "\n",
    "    # Calcular valores promedio de pérdida y exactitud\n",
    "    perdida_train /= nlotes #Promedio de la perdida\n",
    "    exactitud /= train_size #Promedio de la exactitud\n",
    "\n",
    "    print(f\"Perdida promedio: {perdida_train:>8f} | Exactitud: {100*exactitud:>0.1f}%\")\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
